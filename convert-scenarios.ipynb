{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('.', 'data_as_provided')\n",
    "output_path = os.path.join('.', 'data_processed')\n",
    "arc_scenarios_file = os.path.join(data_path, 'ARC Employment Scenarios (45 sectors) v2.xlsx')\n",
    "gb_baseline_file = os.path.join(data_path, 'LAD data by sectors.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = pandas.read_excel(\n",
    "    gb_baseline_file, \n",
    "    sheet_name=['GVA', 'Employment', 'Productivity'], \n",
    "    header=1, \n",
    "    index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "label_lookup = {\n",
    "    'GVA': 'GVA (GBP2016m)',\n",
    "    'Employment': 'Employment (000s)',\n",
    "    'Productivity': 'Productivity (GBP2016 thousands per person in employment)'\n",
    "}\n",
    "\n",
    "def melt_block(df, label, year):\n",
    "    df.index.name = \"sector\"\n",
    "    df = df.reset_index().melt(\n",
    "        id_vars=['sector'], var_name='lad_nm', value_name=label\n",
    "    )\n",
    "    df['year'] = year\n",
    "    df.lad_nm = df.lad_nm.apply(lambda nm: nm.strip())\n",
    "    df = df.set_index(\n",
    "        ['year', 'lad_nm', 'sector']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "for label, df in baseline.items():\n",
    "    # two blocks\n",
    "    dfs.append(\n",
    "        pandas.concat([\n",
    "            melt_block(df[:45], label, 2018),\n",
    "            melt_block(df[48:], label, 2050)\n",
    "        ], axis=0)\n",
    "    )\n",
    "    \n",
    "baseline_all = pandas.concat(dfs, axis=1, levels=['year','lad_nm', 'sector'])\n",
    "baseline_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years * Great Britain LADs * sectors\n",
    "assert len(baseline_all) == 2 * 380 * 45 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = pandas.read_excel(\n",
    "    arc_scenarios_file,\n",
    "    sheet_name=['Baseline', 'Unplanned', 'City Focused', 'New Developments'],\n",
    "    index_col=0,\n",
    "    header=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = variants['Baseline'].iloc[0:45, 0:29]\n",
    "df.index.name = 'sector'\n",
    "df = df.reset_index().melt(\n",
    "    id_vars='sector', var_name='lad_nm', value_name='Employment')\n",
    "assert len(df) == 45*29\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_scenario(s_df, scenario, name, year, row): \n",
    "    step = 45\n",
    "    from_row, to_row = row, row + step\n",
    "    df = s_df.iloc[from_row:to_row, 0:29].copy()\n",
    "    df = df.reset_index().melt(\n",
    "        id_vars=['sector'],\n",
    "        var_name='lad_nm',\n",
    "        value_name=name\n",
    "    )\n",
    "    df['year'] = year\n",
    "    df['scenario'] = scenario\n",
    "    df = df.set_index(\n",
    "        ['scenario', 'year', 'lad_nm', 'sector']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "dfs = []\n",
    "for scenario, s_df in variants.items():\n",
    "    s_df.index.name = 'sector'\n",
    "    s_dfs = [\n",
    "        pandas.concat([\n",
    "            melt_scenario(s_df, scenario, 'Employment', 2018, 0),\n",
    "            melt_scenario(s_df, scenario, 'Employment', 2050, 49),\n",
    "        ], axis=0),\n",
    "        pandas.concat([\n",
    "            melt_scenario(s_df, scenario, 'GVA', 2018, 98),\n",
    "            melt_scenario(s_df, scenario, 'GVA', 2050, 147),\n",
    "        ], axis=0),\n",
    "        pandas.concat([\n",
    "            melt_scenario(s_df, scenario, 'Productivity', 2018, 196),\n",
    "            melt_scenario(s_df, scenario, 'Productivity', 2050, 245),\n",
    "        ], axis=0)\n",
    "    ]\n",
    "    s_df_all = pandas.concat(s_dfs, axis=1, levels=['scenario', 'year', 'lad_nm', 'sector'])\n",
    "    dfs.append(s_df_all)\n",
    "        \n",
    "variants_all = pandas.concat(dfs, axis=0)\n",
    "variants_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(variants_all) == 2 * 29 * 4 * 45  # years * Arc LADs * scenarios * sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add LAD codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_nmcds = pandas.read_csv(os.path.join(data_path, 'lad_nmcd_changes.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_nmcds = lad_nmcds[['lad11nm', 'lad11cd', 'lad16nm', 'lad16cd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_all_lad_nms = set(baseline_all.reset_index().lad_nm.unique())\n",
    "all_lad_nms = set(lad_nmcds.lad11nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lad_nms - baseline_all_lad_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_all_lad_nms - all_lad_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_all = baseline_all.reset_index()\n",
    "baseline_all.lad_nm = baseline_all.lad_nm.replace({\n",
    "    'Anglesey': 'Isle of Anglesey',\n",
    "    'King`s Lynn and West Norfolk': \"King's Lynn and West Norfolk\",\n",
    "    'Rhondda, Cynon, Taff': 'Rhondda Cynon Taf'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_wlad = baseline_all.merge(lad_nmcds, left_on='lad_nm', right_on='lad11nm').drop('lad_nm', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baseline_wlad.lad11nm.unique()), len(baseline_wlad), len(baseline_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_wlad = variants_all.reset_index().merge(lad_nmcds, left_on='lad_nm', right_on='lad11nm').drop('lad_nm', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_wlad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(variants_wlad.lad11nm.unique()), len(variants_wlad), len(variants_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_wlad[(baseline_wlad.lad11nm != baseline_wlad.lad16nm) | (baseline_wlad.lad11cd != baseline_wlad.lad16cd)].lad16nm.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_wlad.to_csv(os.path.join(output_path, 'gb_baseline.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_wlad.to_csv(os.path.join(output_path, 'arc_variants.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged, separate file-per-scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = baseline_wlad[\n",
    "    ['year', 'sector', 'Employment', 'GVA', 'lad11nm', 'lad11cd', 'lad16nm', 'lad16cd']\n",
    "].rename(columns={\n",
    "    'Employment': 'employment', \n",
    "    'GVA': 'gva'\n",
    "})\n",
    "base = base[base.year.isin(range(2015, 2051))]\n",
    "assert len(base) == 2 * 45 * 380  # years * sectors * LADs in GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Northern Ireland rGVA by LAD and sector\n",
    "\n",
    "Look at projection for Northern Ireland based on 2015 industry composition, UK average growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, filename, force=False):\n",
    "    if force or not os.path.exists(filename):\n",
    "        r = requests.get(url, stream=True)\n",
    "        with open(filename, 'wb') as fd:\n",
    "            for chunk in r.iter_content(chunk_size=128):\n",
    "                fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal and real regional gross value added (balanced) by industry, NUTS1, NUTS2, NUTS3, 1998-2017\n",
    "rgva_uk_ind_url = \"https://www.ons.gov.uk/file?uri=/economy/grossvalueaddedgva/datasets/nominalandrealregionalgrossvalueaddedbalancedbyindustry/current/nominalandrealregionalgvabbyindustry.xlsx\"\n",
    "download(rgva_uk_ind_url, os.path.join(data_path, 'rgva_uk_industry.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgva = pandas.read_excel(\n",
    "    os.path.join(data_path, 'rgva_uk_industry.xlsx'), \n",
    "    sheet_name='Table3c', \n",
    "    header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgva = rgva[:13783]  # skip footnotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgva.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick division-level values (avoid double-count sectors, total)\n",
    "p = re.compile('^\\d')\n",
    "rgva = rgva[rgva.SIC07.apply(lambda sic: bool(re.match(p, str(sic))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_nuts3_lu_url = \"http://geoportal1-ons.opendata.arcgis.com/datasets/e1e5de6c5fcc40c78adb03d84a2d299d_0.csv\"\n",
    "download(lad_nuts3_lu_url, os.path.join(data_path, \"lad_nuts_lu.csv\"))\n",
    "lad_nuts = pandas.read_csv(os.path.join(data_path, 'lad_nuts_lu.csv'))\n",
    "lad_nuts = lad_nuts[['LAD16CD', 'LAD16NM', 'NUTS318CD']].sort_values('LAD16CD').drop_duplicates().rename(columns={\n",
    "    'LAD16CD': 'lad16cd',\n",
    "    'LAD16NM': 'lad16nm',\n",
    "    'NUTS318CD': 'nuts318cd'\n",
    "})\n",
    "lad_nuts.head(), len(lad_nuts.nuts318cd.unique()), len(lad_nuts.lad16cd.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgva15 = rgva.merge(\n",
    "    lad_nuts, left_on='Region code', right_on='nuts318cd', how='outer'\n",
    ").rename(columns={\n",
    "    'Region name': 'nuts318nm',\n",
    "    2015: 'gva15_nuts_division_group',\n",
    "    'SIC07': 'sic07_division_group',\n",
    "    'SIC07 description': 'sic07_division_group_description'\n",
    "})[[\n",
    "    'lad16cd',\n",
    "    'lad16nm',\n",
    "    'nuts318cd',\n",
    "    'nuts318nm',\n",
    "    'sic07_division_group',\n",
    "    'sic07_division_group_description',\n",
    "    'gva15_nuts_division_group'\n",
    "]]\n",
    "rgva15.sic07_division_group = rgva15.sic07_division_group.astype(str)\n",
    "rgva15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_map = pandas.read_csv(os.path.join('data_as_provided','map_sectors.csv'))\n",
    "sector_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgva15.sic07_division_group = rgva15.sic07_division_group.apply(lambda d: d.replace('-', ' to '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgva15s = rgva15.merge(sector_map, on='sic07_division_group', how='outer')\n",
    "rgva15s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disaggregate UK 2015 rGVA to LADs and SIC07 divisions\n",
    "\n",
    "Very coarse, purely proportional split - could be improved e.g. by using BRES employment industry percentage figures for current split to full divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_for_disagg = rgva15s.groupby(['nuts318cd', 'sic07_division_group']).count()[['lad16cd']]\n",
    "count_for_disagg.columns = ['nuts_division_group_count']\n",
    "count_for_disagg = count_for_disagg.reset_index()\n",
    "rgva15sd = rgva15s.merge(count_for_disagg, on=['nuts318cd', 'sic07_division_group'], how='left')\n",
    "rgva15sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgva15sd['gva15_lad_division'] = rgva15sd.gva15_nuts_division_group / rgva15sd.nuts_division_group_count\n",
    "rgva15_lad_division = rgva15sd[[\n",
    "    'lad16cd', 'itrc_sector', 'sic07_division', 'gva15_lad_division'\n",
    "]]\n",
    "rgva15_lad_division.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_for_disagg = rgva15_lad_division.groupby(['lad16cd']).sum()[['gva15_lad_division']]\n",
    "sum_for_disagg.columns = ['gva15_lad_total']\n",
    "rgva15_lad_division_d = rgva15_lad_division.merge(sum_for_disagg.reset_index(), on='lad16cd')\n",
    "rgva15_lad_division_d['gva15_lad_division_proportion'] = rgva15_lad_division_d.gva15_lad_division / rgva15_lad_division_d.gva15_lad_total\n",
    "rgva15_lad_division_d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project NI regions as proportion of NI total\n",
    "\n",
    "Where future NI total is projected assuming NI growth equals GB growth:\n",
    "\n",
    "NI GVA in 2015 * (GB GVA in future year / GB GVA in 2015) = NI GVA in future year\n",
    "\n",
    "And NI future regional/sectoral GVA follows the same proportional structure as in 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni_rgva = rgva15_lad_division_d[rgva15_lad_division_d.lad16cd.str.startswith('N')].copy()\n",
    "ni_rgva.sort_values(['lad16cd', 'sic07_division']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni_rgva_for_proj = ni_rgva[['lad16cd', 'gva15_lad_total']].drop_duplicates()\n",
    "ni_rgva_for_proj['gva15_lad_ni_proportion'] = ni_rgva_for_proj.gva15_lad_total / ni_rgva_for_proj.gva15_lad_total.sum()\n",
    "ni_rgva_for_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_base = base.copy()[['year', 'lad16cd', 'gva', 'employment']]\n",
    "gb_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_growth = gb_base.groupby('year').sum()[['gva']].reset_index()\n",
    "gb_growth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ni_rgva15 = ni_rgva_for_proj.gva15_lad_total.sum()\n",
    "total_uk_rgva15 = rgva15_lad_division_d.gva15_lad_division.sum()\n",
    "total_gb_rgva15 = total_uk_rgva15 - total_ni_rgva15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in gb_growth.year:\n",
    "    df = ni_rgva_for_proj.copy()\n",
    "    df['year'] = year\n",
    "    gb_future = float(gb_growth[gb_growth.year == year].gva)\n",
    "    ni_future = total_ni_rgva15 * (gb_future / total_gb_rgva15)\n",
    "    df['gva'] = df.gva15_lad_ni_proportion * ni_future\n",
    "    dfs.append(df)\n",
    "    \n",
    "ni_base = pandas.concat(dfs, axis=0)[['year', 'lad16cd', 'gva']]\n",
    "ni_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disaggregate projections by SIC07 division, reaggregate to ITRC sector\n",
    "\n",
    "Assuming constant sectoral shares of GVA, projected LAD sectoral GVA is (projected LAD GVA * (current LAD sectoral GVA / current LAD GVA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni_disagg = ni_base.merge(rgva15_lad_division_d, on='lad16cd', how='left').rename(columns={'year': 'timestep'})\n",
    "ni_disagg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni_disagg['gva_lad_division'] = ni_disagg.gva * ni_disagg.gva15_lad_division_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni_disagg = ni_disagg.groupby(\n",
    "    ['timestep', 'lad16cd', 'itrc_sector']\n",
    ").sum().reset_index()[\n",
    "    ['timestep', 'lad16cd', 'itrc_sector', 'gva_lad_division']\n",
    "].dropna().rename(\n",
    "    columns={'gva_lad_division': 'gva_per_sector'}\n",
    ")\n",
    "ni_disagg = ni_disagg[ni_disagg.itrc_sector != 46]  # drop unallocated/household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(ni_disagg) == 2 * 11 * 45  # timestep * NI LADs * 45 sectors\n",
    "ni_disagg['employment'] = 0  # no estimate for NI employment\n",
    "ni_disagg.sort_values(by=['timestep', 'lad16cd', 'itrc_sector']).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add itrc sector codes to GB base\n",
    "base.sector = base.sector.apply(lambda d: d.replace(', etc', ' etc'))\n",
    "sector_ids = sector_map[['itrc_sector', 'itrc_sector_description']].drop_duplicates()\n",
    "sector_ids.itrc_sector_description = sector_ids.itrc_sector_description.apply(lambda d: d.replace(', etc', ' etc'))\n",
    "gb_disagg = base.merge(\n",
    "    sector_ids, left_on='sector', right_on='itrc_sector_description', how='left'\n",
    ")[\n",
    "    ['year', 'lad16cd', 'itrc_sector', 'gva', 'employment']\n",
    "].rename(\n",
    "    columns={'year': 'timestep', 'gva': 'gva_per_sector'}\n",
    ")\n",
    "assert len(gb_disagg) == 2 * 380 * 45\n",
    "gb_disagg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_base = pandas.concat([gb_disagg, ni_disagg], axis=0)\n",
    "assert len(full_base) == 391 * 45 * 2\n",
    "full_base.to_csv(os.path.join(output_path, 'uk_baseline.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stitch scenario projections with baseline UK (GVA by LAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_wlad = variants_wlad.rename(columns={'lad16cd': 'lad_uk_2016'})\n",
    "full_base = full_base.rename(columns={'lad16cd': 'lad_uk_2016'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_gva = full_base[['timestep', 'lad_uk_2016', 'itrc_sector', 'gva_per_sector']].copy()\n",
    "base_emp = full_base[['timestep', 'lad_uk_2016', 'itrc_sector', 'employment']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 2018/2050 for all non-Arc LADs\n",
    "base_gva = base_gva[~base_gva.lad_uk_2016.isin(variants_wlad.lad_uk_2016.unique())]\n",
    "assert len(base_gva) == (391 - 29) * 45 * 2\n",
    "base_emp = base_emp[~base_emp.lad_uk_2016.isin(variants_wlad.lad_uk_2016.unique())]\n",
    "assert len(base_emp) == (391 - 29) * 45 * 2\n",
    "base_gva.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add itrc sector codes to GB base\n",
    "variants_wlad.sector = variants_wlad.sector.apply(lambda d: d.replace(', etc', ' etc'))\n",
    "variants_wlad = variants_wlad.merge(\n",
    "    sector_ids, left_on='sector', right_on='itrc_sector_description', how='left'\n",
    ")[\n",
    "    ['year', 'lad_uk_2016', 'itrc_sector', 'GVA', 'Employment', 'scenario']\n",
    "].rename(\n",
    "    columns={'year': 'timestep', 'GVA': 'gva_per_sector', 'Employment': 'employment'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_wlad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(data, lower_year, upper_year, projected_year):\n",
    "    proportion = (projected_year - lower_year) / (upper_year - lower_year)\n",
    "    step = proportion * (data[upper_year] - data[lower_year])\n",
    "    return data[lower_year] + step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_region_sector_df(df, value_colname, timesteps):\n",
    "    df[\"rs\"] = df.apply(lambda d: (d.lad_uk_2016, d.itrc_sector), axis=1) # hack index as tuple\n",
    "    df = df.pivot(index=\"rs\", columns=\"timestep\", values=value_colname)\n",
    "    for year in timeline:\n",
    "        df[year] = interpolate(df, 2018, 2050, year)\n",
    "    df = df.reset_index()\n",
    "    df['itrc_sector'] = df.rs.apply(lambda rs: rs[1])\n",
    "    df['lad_uk_2016'] = df.rs.apply(lambda rs: rs[0])\n",
    "    df.drop(\"rs\", axis=1, inplace=True)\n",
    "    return df.melt(id_vars=['itrc_sector', 'lad_uk_2016'], value_name=value_colname)\n",
    "\n",
    "def interpolate_region_df(df, value_colname, timesteps):\n",
    "    df = df.pivot(index=\"lad_uk_2016\", columns=\"timestep\", values=value_colname)\n",
    "    for year in timeline:\n",
    "        df[year] = interpolate(df, 2018, 2050, year)\n",
    "    df = df.reset_index()\n",
    "    return df.melt(id_vars=['itrc_sector', 'lad_uk_2016'], value_name=value_colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = list(range(2015, 2051))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up variants dict\n",
    "vard = {}\n",
    "\n",
    "for scenario in ('Baseline', 'Unplanned', 'City Focused', 'New Developments'):\n",
    "    var = variants_wlad[\n",
    "        variants_wlad.scenario == scenario\n",
    "    ][\n",
    "        ['timestep', 'employment', 'gva_per_sector', 'lad_uk_2016', 'itrc_sector']\n",
    "    ]\n",
    "    vard[scenario] = var.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check baseline 'scenario' matches full baseline\n",
    "arc_baseline_from_scenario = vard['Baseline'][\n",
    "    ['timestep','lad_uk_2016','itrc_sector','gva_per_sector','employment']\n",
    "].sort_values(['timestep','lad_uk_2016','itrc_sector']).reset_index(drop=True)\n",
    "\n",
    "arc_baseline_from_gb = full_base[full_base.lad_uk_2016.isin(variants_wlad.lad_uk_2016.unique())][\n",
    "    ['timestep','lad_uk_2016','itrc_sector','gva_per_sector','employment']\n",
    "].sort_values(['timestep','lad_uk_2016','itrc_sector']).reset_index(drop=True)\n",
    "\n",
    "import pandas.testing\n",
    "pandas.testing.assert_frame_equal(arc_baseline_from_scenario, arc_baseline_from_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_for_smif(df, var_name, scenario_key):\n",
    "    # full, by lad/sector\n",
    "    df.to_csv(os.path.join(output_path, 'arc_{}_by_sector__{}.csv'.format(var_name, scenario_key)), index=False)\n",
    "    \n",
    "    # by lad / energy demand sector    \n",
    "    energy_demand_sector_subset = [2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 17, 19, 23, 27, 28, 29, 35, 40, 41]\n",
    "    df_ed = df[df.itrc_sector.isin(energy_demand_sector_subset)]\n",
    "    df_ed.to_csv(os.path.join(output_path, 'arc_{}_by_sector_for_energy_demand__{}.csv'.format(var_name, scenario_key)), index=False)\n",
    "    \n",
    "    # by lad (drop sectors)\n",
    "    df_by_lad = df.drop('itrc_sector', axis=1).groupby(['timestep', 'lad_uk_2016']).sum().reset_index() \\\n",
    "        .rename(columns={'gva_per_sector': 'gva'})\n",
    "    df_by_lad.to_csv(os.path.join(output_path, 'arc_{}__{}.csv'.format(var_name, scenario_key)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario, key in (('Baseline', 'baseline'), ('Unplanned', '0-unplanned'), ('New Developments', '1-new-cities'), ('City Focused', '2-expansion')):\n",
    "    # split / stitch\n",
    "    scenario_emp = pandas.concat(\n",
    "        [base_emp, vard[scenario][['timestep', 'lad_uk_2016', 'itrc_sector', 'employment']]], axis=0, sort=False\n",
    "    ).sort_values(\n",
    "        ['timestep', 'lad_uk_2016', 'itrc_sector']\n",
    "    )\n",
    "    scenario_gva = pandas.concat(\n",
    "        [base_gva, vard[scenario][['timestep', 'lad_uk_2016', 'itrc_sector', 'gva_per_sector']]], axis=0, sort=False\n",
    "    ).sort_values(\n",
    "        ['timestep', 'lad_uk_2016', 'itrc_sector']\n",
    "    )\n",
    "    \n",
    "    # Interpolate\n",
    "    scenario_emp = interpolate_region_sector_df(scenario_emp, 'employment', timeline)\n",
    "    scenario_gva = interpolate_region_sector_df(scenario_gva, 'gva_per_sector', timeline)\n",
    "    \n",
    "    # Output to CSV\n",
    "    output_for_smif(scenario_emp, 'employment', key)\n",
    "    output_for_smif(scenario_gva, 'gva', key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
